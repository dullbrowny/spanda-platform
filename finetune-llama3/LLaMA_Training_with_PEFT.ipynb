{"cells":[{"cell_type":"markdown","metadata":{},"source":["# LLaMA Training with PEFT"]},{"cell_type":"markdown","metadata":{},"source":["# Step 0: Install dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting pandas\n","  Downloading pandas-2.2.2-cp310-cp310-win_amd64.whl.metadata (19 kB)\n","Requirement already satisfied: numpy>=1.22.4 in d:\\verba_1.01\\venv\\lib\\site-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in d:\\verba_1.01\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n","Collecting pytz>=2020.1 (from pandas)\n","  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n","Collecting tzdata>=2022.7 (from pandas)\n","  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Requirement already satisfied: six>=1.5 in d:\\verba_1.01\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Downloading pandas-2.2.2-cp310-cp310-win_amd64.whl (11.6 MB)\n","   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n","   ---------------------------------------- 0.1/11.6 MB 2.2 MB/s eta 0:00:06\n","   - -------------------------------------- 0.3/11.6 MB 3.5 MB/s eta 0:00:04\n","   -- ------------------------------------- 0.8/11.6 MB 5.7 MB/s eta 0:00:02\n","   ----- ---------------------------------- 1.7/11.6 MB 9.2 MB/s eta 0:00:02\n","   -------- ------------------------------- 2.5/11.6 MB 10.4 MB/s eta 0:00:01\n","   ------------ --------------------------- 3.7/11.6 MB 13.1 MB/s eta 0:00:01\n","   --------------- ------------------------ 4.5/11.6 MB 14.5 MB/s eta 0:00:01\n","   ------------------- -------------------- 5.5/11.6 MB 15.4 MB/s eta 0:00:01\n","   --------------------- ------------------ 6.2/11.6 MB 15.3 MB/s eta 0:00:01\n","   ------------------------- -------------- 7.5/11.6 MB 16.5 MB/s eta 0:00:01\n","   --------------------------- ------------ 8.1/11.6 MB 16.7 MB/s eta 0:00:01\n","   ------------------------------- -------- 9.2/11.6 MB 16.2 MB/s eta 0:00:01\n","   ----------------------------------- ---- 10.4/11.6 MB 18.2 MB/s eta 0:00:01\n","   ---------------------------------------  11.6/11.6 MB 21.8 MB/s eta 0:00:01\n","   ---------------------------------------- 11.6/11.6 MB 20.5 MB/s eta 0:00:00\n","Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n","   ---------------------------------------- 0.0/505.5 kB ? eta -:--:--\n","   --------------------------------------- 505.5/505.5 kB 16.0 MB/s eta 0:00:00\n","Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n","   ---------------------------------------- 0.0/345.4 kB ? eta -:--:--\n","   --------------------------------------- 345.4/345.4 kB 22.3 MB/s eta 0:00:00\n","Installing collected packages: pytz, tzdata, pandas\n","Successfully installed pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting datasets\n","  Using cached datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: filelock in d:\\verba_1.01\\venv\\lib\\site-packages (from datasets) (3.14.0)\n","Requirement already satisfied: numpy>=1.17 in d:\\verba_1.01\\venv\\lib\\site-packages (from datasets) (1.26.4)\n","Collecting pyarrow>=15.0.0 (from datasets)\n","  Downloading pyarrow-16.1.0-cp310-cp310-win_amd64.whl.metadata (3.1 kB)\n","Collecting pyarrow-hotfix (from datasets)\n","  Using cached pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in d:\\verba_1.01\\venv\\lib\\site-packages (from datasets) (2.2.2)\n","Collecting requests>=2.32.2 (from datasets)\n","  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n","Requirement already satisfied: tqdm>=4.66.3 in d:\\verba_1.01\\venv\\lib\\site-packages (from datasets) (4.66.4)\n","Collecting xxhash (from datasets)\n","  Using cached xxhash-3.4.1-cp310-cp310-win_amd64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets)\n","  Using cached multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n","Requirement already satisfied: aiohttp in d:\\verba_1.01\\venv\\lib\\site-packages (from datasets) (3.9.5)\n","Requirement already satisfied: huggingface-hub>=0.21.2 in d:\\verba_1.01\\venv\\lib\\site-packages (from datasets) (0.23.2)\n","Requirement already satisfied: packaging in d:\\verba_1.01\\venv\\lib\\site-packages (from datasets) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from datasets) (6.0.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in d:\\verba_1.01\\venv\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in d:\\verba_1.01\\venv\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\verba_1.01\\venv\\lib\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2024.2.2)\n","Requirement already satisfied: colorama in d:\\verba_1.01\\venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in d:\\verba_1.01\\venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in d:\\verba_1.01\\venv\\lib\\site-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in d:\\verba_1.01\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Using cached datasets-2.20.0-py3-none-any.whl (547 kB)\n","Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n","Downloading pyarrow-16.1.0-cp310-cp310-win_amd64.whl (25.9 MB)\n","   ---------------------------------------- 0.0/25.9 MB ? eta -:--:--\n","   ---------------------------------------- 0.1/25.9 MB 2.2 MB/s eta 0:00:12\n","   ---------------------------------------- 0.3/25.9 MB 3.3 MB/s eta 0:00:08\n","   - -------------------------------------- 0.9/25.9 MB 6.4 MB/s eta 0:00:04\n","   -- ------------------------------------- 1.8/25.9 MB 9.6 MB/s eta 0:00:03\n","   --- ------------------------------------ 2.5/25.9 MB 10.5 MB/s eta 0:00:03\n","   ---- ----------------------------------- 3.2/25.9 MB 11.4 MB/s eta 0:00:02\n","   ------ --------------------------------- 3.9/25.9 MB 12.0 MB/s eta 0:00:02\n","   ------- -------------------------------- 5.1/25.9 MB 13.5 MB/s eta 0:00:02\n","   -------- ------------------------------- 5.4/25.9 MB 12.8 MB/s eta 0:00:02\n","   ---------- ----------------------------- 6.7/25.9 MB 14.3 MB/s eta 0:00:02\n","   ----------- ---------------------------- 7.5/25.9 MB 14.6 MB/s eta 0:00:02\n","   ------------- -------------------------- 8.7/25.9 MB 15.4 MB/s eta 0:00:02\n","   --------------- ------------------------ 9.9/25.9 MB 16.3 MB/s eta 0:00:01\n","   ---------------- ----------------------- 10.9/25.9 MB 19.9 MB/s eta 0:00:01\n","   ----------------- ---------------------- 11.5/25.9 MB 19.3 MB/s eta 0:00:01\n","   ------------------- -------------------- 12.8/25.9 MB 19.8 MB/s eta 0:00:01\n","   -------------------- ------------------- 13.2/25.9 MB 19.2 MB/s eta 0:00:01\n","   ---------------------- ----------------- 14.5/25.9 MB 20.5 MB/s eta 0:00:01\n","   ------------------------ --------------- 15.7/25.9 MB 21.9 MB/s eta 0:00:01\n","   ------------------------- -------------- 16.4/25.9 MB 21.1 MB/s eta 0:00:01\n","   ------------------------- -------------- 16.4/25.9 MB 21.1 MB/s eta 0:00:01\n","   -------------------------- ------------- 17.4/25.9 MB 18.7 MB/s eta 0:00:01\n","   ---------------------------- ----------- 18.7/25.9 MB 19.8 MB/s eta 0:00:01\n","   ------------------------------ --------- 19.8/25.9 MB 19.2 MB/s eta 0:00:01\n","   -------------------------------- ------- 21.0/25.9 MB 19.2 MB/s eta 0:00:01\n","   ---------------------------------- ----- 22.1/25.9 MB 20.5 MB/s eta 0:00:01\n","   ------------------------------------ --- 23.3/25.9 MB 20.5 MB/s eta 0:00:01\n","   ------------------------------------ --- 23.9/25.9 MB 20.5 MB/s eta 0:00:01\n","   -------------------------------------- - 25.1/25.9 MB 20.5 MB/s eta 0:00:01\n","   ---------------------------------------  25.9/25.9 MB 20.5 MB/s eta 0:00:01\n","   ---------------------------------------- 25.9/25.9 MB 18.7 MB/s eta 0:00:00\n","Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n","Using cached multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Using cached xxhash-3.4.1-cp310-cp310-win_amd64.whl (29 kB)\n","Installing collected packages: xxhash, requests, pyarrow-hotfix, pyarrow, dill, multiprocess, datasets\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.31.0\n","    Uninstalling requests-2.31.0:\n","      Successfully uninstalled requests-2.31.0\n","Successfully installed datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 pyarrow-16.1.0 pyarrow-hotfix-0.6 requests-2.32.3 xxhash-3.4.1\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","weaviate-client 3.23.1 requires requests<=2.31.0,>=2.28.0, but you have requests 2.32.3 which is incompatible.\n","goldenverba 1.0.2 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n"]},{"name":"stdout","output_type":"stream","text":["Collecting seaborn\n","  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n","Requirement already satisfied: numpy!=1.24.0,>=1.20 in d:\\verba_1.01\\venv\\lib\\site-packages (from seaborn) (1.26.4)\n","Requirement already satisfied: pandas>=1.2 in d:\\verba_1.01\\venv\\lib\\site-packages (from seaborn) (2.2.2)\n","Collecting matplotlib!=3.6.1,>=3.4 (from seaborn)\n","  Using cached matplotlib-3.9.0-cp310-cp310-win_amd64.whl.metadata (11 kB)\n","Collecting contourpy>=1.0.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n","  Using cached contourpy-1.2.1-cp310-cp310-win_amd64.whl.metadata (5.8 kB)\n","Collecting cycler>=0.10 (from matplotlib!=3.6.1,>=3.4->seaborn)\n","  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n","Collecting fonttools>=4.22.0 (from matplotlib!=3.6.1,>=3.4->seaborn)\n","  Downloading fonttools-4.53.0-cp310-cp310-win_amd64.whl.metadata (165 kB)\n","     ---------------------------------------- 0.0/165.5 kB ? eta -:--:--\n","     ---------------- ---------------------- 71.7/165.5 kB 2.0 MB/s eta 0:00:01\n","     -------------------------------------- 165.5/165.5 kB 2.5 MB/s eta 0:00:00\n","Collecting kiwisolver>=1.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n","  Using cached kiwisolver-1.4.5-cp310-cp310-win_amd64.whl.metadata (6.5 kB)\n","Requirement already satisfied: packaging>=20.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.0)\n","Collecting pillow>=8 (from matplotlib!=3.6.1,>=3.4->seaborn)\n","  Using cached pillow-10.3.0-cp310-cp310-win_amd64.whl.metadata (9.4 kB)\n","Collecting pyparsing>=2.3.1 (from matplotlib!=3.6.1,>=3.4->seaborn)\n","  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: python-dateutil>=2.7 in d:\\verba_1.01\\venv\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in d:\\verba_1.01\\venv\\lib\\site-packages (from pandas>=1.2->seaborn) (2024.1)\n","Requirement already satisfied: six>=1.5 in d:\\verba_1.01\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n","Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n","Using cached matplotlib-3.9.0-cp310-cp310-win_amd64.whl (8.0 MB)\n","Using cached contourpy-1.2.1-cp310-cp310-win_amd64.whl (187 kB)\n","Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n","Downloading fonttools-4.53.0-cp310-cp310-win_amd64.whl (2.2 MB)\n","   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n","   -------- ------------------------------- 0.5/2.2 MB 9.8 MB/s eta 0:00:01\n","   ----------------- ---------------------- 1.0/2.2 MB 10.3 MB/s eta 0:00:01\n","   ------------------------------ --------- 1.7/2.2 MB 11.8 MB/s eta 0:00:01\n","   ---------------------------------------  2.2/2.2 MB 11.7 MB/s eta 0:00:01\n","   ---------------------------------------- 2.2/2.2 MB 10.8 MB/s eta 0:00:00\n","Using cached kiwisolver-1.4.5-cp310-cp310-win_amd64.whl (56 kB)\n","Using cached pillow-10.3.0-cp310-cp310-win_amd64.whl (2.5 MB)\n","Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n","Installing collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib, seaborn\n","Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.53.0 kiwisolver-1.4.5 matplotlib-3.9.0 pillow-10.3.0 pyparsing-3.1.2 seaborn-0.13.2\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: matplotlib in d:\\verba_1.01\\venv\\lib\\site-packages (3.9.0)\n","Requirement already satisfied: contourpy>=1.0.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from matplotlib) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in d:\\verba_1.01\\venv\\lib\\site-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from matplotlib) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: numpy>=1.23 in d:\\verba_1.01\\venv\\lib\\site-packages (from matplotlib) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from matplotlib) (24.0)\n","Requirement already satisfied: pillow>=8 in d:\\verba_1.01\\venv\\lib\\site-packages (from matplotlib) (10.3.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from matplotlib) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in d:\\verba_1.01\\venv\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in d:\\verba_1.01\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: transformers in d:\\verba_1.01\\venv\\lib\\site-packages (4.41.2)\n","Requirement already satisfied: filelock in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers) (3.14.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers) (0.23.2)\n","Requirement already satisfied: numpy>=1.17 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.5.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\verba_1.01\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.0)\n","Requirement already satisfied: colorama in d:\\verba_1.01\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests->transformers) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests->transformers) (2024.2.2)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: huggingface_hub in d:\\verba_1.01\\venv\\lib\\site-packages (0.23.2)\n","Requirement already satisfied: filelock in d:\\verba_1.01\\venv\\lib\\site-packages (from huggingface_hub) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from huggingface_hub) (2024.5.0)\n","Requirement already satisfied: packaging>=20.9 in d:\\verba_1.01\\venv\\lib\\site-packages (from huggingface_hub) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from huggingface_hub) (6.0.1)\n","Requirement already satisfied: requests in d:\\verba_1.01\\venv\\lib\\site-packages (from huggingface_hub) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from huggingface_hub) (4.66.4)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\verba_1.01\\venv\\lib\\site-packages (from huggingface_hub) (4.12.0)\n","Requirement already satisfied: colorama in d:\\verba_1.01\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests->huggingface_hub) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests->huggingface_hub) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests->huggingface_hub) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests->huggingface_hub) (2024.2.2)\n","Note: you may need to restart the kernel to use updated packages.\n","Requirement already satisfied: torch in d:\\verba_1.01\\venv\\lib\\site-packages (2.3.0)\n","Requirement already satisfied: filelock in d:\\verba_1.01\\venv\\lib\\site-packages (from torch) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from torch) (4.12.0)\n","Requirement already satisfied: sympy in d:\\verba_1.01\\venv\\lib\\site-packages (from torch) (1.12.1)\n","Requirement already satisfied: networkx in d:\\verba_1.01\\venv\\lib\\site-packages (from torch) (3.3)\n","Requirement already satisfied: jinja2 in d:\\verba_1.01\\venv\\lib\\site-packages (from torch) (3.1.4)\n","Requirement already satisfied: fsspec in d:\\verba_1.01\\venv\\lib\\site-packages (from torch) (2024.5.0)\n","Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from torch) (2021.4.0)\n","Requirement already satisfied: intel-openmp==2021.* in d:\\verba_1.01\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n","Requirement already satisfied: tbb==2021.* in d:\\verba_1.01\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting peft\n","  Using cached peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.17 in d:\\verba_1.01\\venv\\lib\\site-packages (from peft) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from peft) (24.0)\n","Requirement already satisfied: psutil in d:\\verba_1.01\\venv\\lib\\site-packages (from peft) (5.9.8)\n","Requirement already satisfied: pyyaml in d:\\verba_1.01\\venv\\lib\\site-packages (from peft) (6.0.1)\n","Requirement already satisfied: torch>=1.13.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from peft) (2.3.0)\n","Requirement already satisfied: transformers in d:\\verba_1.01\\venv\\lib\\site-packages (from peft) (4.41.2)\n","Requirement already satisfied: tqdm in d:\\verba_1.01\\venv\\lib\\site-packages (from peft) (4.66.4)\n","Requirement already satisfied: accelerate>=0.21.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from peft) (0.30.1)\n","Requirement already satisfied: safetensors in d:\\verba_1.01\\venv\\lib\\site-packages (from peft) (0.4.3)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from peft) (0.23.2)\n","Requirement already satisfied: filelock in d:\\verba_1.01\\venv\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (3.14.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2024.5.0)\n","Requirement already satisfied: requests in d:\\verba_1.01\\venv\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\verba_1.01\\venv\\lib\\site-packages (from huggingface-hub>=0.17.0->peft) (4.12.0)\n","Requirement already satisfied: sympy in d:\\verba_1.01\\venv\\lib\\site-packages (from torch>=1.13.0->peft) (1.12.1)\n","Requirement already satisfied: networkx in d:\\verba_1.01\\venv\\lib\\site-packages (from torch>=1.13.0->peft) (3.3)\n","Requirement already satisfied: jinja2 in d:\\verba_1.01\\venv\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.4)\n","Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from torch>=1.13.0->peft) (2021.4.0)\n","Requirement already satisfied: colorama in d:\\verba_1.01\\venv\\lib\\site-packages (from tqdm->peft) (0.4.6)\n","Requirement already satisfied: regex!=2019.12.17 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers->peft) (2024.5.15)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers->peft) (0.19.1)\n","Requirement already satisfied: intel-openmp==2021.* in d:\\verba_1.01\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.13.0->peft) (2021.4.0)\n","Requirement already satisfied: tbb==2021.* in d:\\verba_1.01\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.13.0->peft) (2021.12.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.2.2)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n","Using cached peft-0.11.1-py3-none-any.whl (251 kB)\n","Installing collected packages: peft\n","Successfully installed peft-0.11.1\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting trl\n","  Using cached trl-0.9.4-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: torch>=1.4.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from trl) (2.3.0)\n","Requirement already satisfied: transformers>=4.31.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from trl) (4.41.2)\n","Requirement already satisfied: numpy>=1.18.2 in d:\\verba_1.01\\venv\\lib\\site-packages (from trl) (1.26.4)\n","Requirement already satisfied: accelerate in d:\\verba_1.01\\venv\\lib\\site-packages (from trl) (0.30.1)\n","Requirement already satisfied: datasets in d:\\verba_1.01\\venv\\lib\\site-packages (from trl) (2.20.0)\n","Collecting tyro>=0.5.11 (from trl)\n","  Using cached tyro-0.8.4-py3-none-any.whl.metadata (7.9 kB)\n","Requirement already satisfied: filelock in d:\\verba_1.01\\venv\\lib\\site-packages (from torch>=1.4.0->trl) (3.14.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from torch>=1.4.0->trl) (4.12.0)\n","Requirement already satisfied: sympy in d:\\verba_1.01\\venv\\lib\\site-packages (from torch>=1.4.0->trl) (1.12.1)\n","Requirement already satisfied: networkx in d:\\verba_1.01\\venv\\lib\\site-packages (from torch>=1.4.0->trl) (3.3)\n","Requirement already satisfied: jinja2 in d:\\verba_1.01\\venv\\lib\\site-packages (from torch>=1.4.0->trl) (3.1.4)\n","Requirement already satisfied: fsspec in d:\\verba_1.01\\venv\\lib\\site-packages (from torch>=1.4.0->trl) (2024.5.0)\n","Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from torch>=1.4.0->trl) (2021.4.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers>=4.31.0->trl) (0.23.2)\n","Requirement already satisfied: packaging>=20.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers>=4.31.0->trl) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers>=4.31.0->trl) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers>=4.31.0->trl) (2024.5.15)\n","Requirement already satisfied: requests in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers>=4.31.0->trl) (2.32.3)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers>=4.31.0->trl) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers>=4.31.0->trl) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in d:\\verba_1.01\\venv\\lib\\site-packages (from transformers>=4.31.0->trl) (4.66.4)\n","Requirement already satisfied: docstring-parser>=0.14.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from tyro>=0.5.11->trl) (0.16)\n","Collecting rich>=11.1.0 (from tyro>=0.5.11->trl)\n","  Using cached rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n","Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl)\n","  Using cached shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: colorama>=0.4.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from tyro>=0.5.11->trl) (0.4.6)\n","Requirement already satisfied: psutil in d:\\verba_1.01\\venv\\lib\\site-packages (from accelerate->trl) (5.9.8)\n","Requirement already satisfied: pyarrow>=15.0.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from datasets->trl) (16.1.0)\n","Requirement already satisfied: pyarrow-hotfix in d:\\verba_1.01\\venv\\lib\\site-packages (from datasets->trl) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from datasets->trl) (0.3.8)\n","Requirement already satisfied: pandas in d:\\verba_1.01\\venv\\lib\\site-packages (from datasets->trl) (2.2.2)\n","Requirement already satisfied: xxhash in d:\\verba_1.01\\venv\\lib\\site-packages (from datasets->trl) (3.4.1)\n","Requirement already satisfied: multiprocess in d:\\verba_1.01\\venv\\lib\\site-packages (from datasets->trl) (0.70.16)\n","Requirement already satisfied: aiohttp in d:\\verba_1.01\\venv\\lib\\site-packages (from datasets->trl) (3.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in d:\\verba_1.01\\venv\\lib\\site-packages (from aiohttp->datasets->trl) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from aiohttp->datasets->trl) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from aiohttp->datasets->trl) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in d:\\verba_1.01\\venv\\lib\\site-packages (from aiohttp->datasets->trl) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from aiohttp->datasets->trl) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from aiohttp->datasets->trl) (4.0.3)\n","Requirement already satisfied: intel-openmp==2021.* in d:\\verba_1.01\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.4.0->trl) (2021.4.0)\n","Requirement already satisfied: tbb==2021.* in d:\\verba_1.01\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.4.0->trl) (2021.12.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests->transformers>=4.31.0->trl) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests->transformers>=4.31.0->trl) (2.2.1)\n","Requirement already satisfied: certifi>=2017.4.17 in d:\\verba_1.01\\venv\\lib\\site-packages (from requests->transformers>=4.31.0->trl) (2024.2.2)\n","Collecting markdown-it-py>=2.2.0 (from rich>=11.1.0->tyro>=0.5.11->trl)\n","  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.18.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n","Requirement already satisfied: python-dateutil>=2.8.2 in d:\\verba_1.01\\venv\\lib\\site-packages (from pandas->datasets->trl) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from pandas->datasets->trl) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in d:\\verba_1.01\\venv\\lib\\site-packages (from pandas->datasets->trl) (2024.1)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n","Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl)\n","  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n","Requirement already satisfied: six>=1.5 in d:\\verba_1.01\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n","Using cached trl-0.9.4-py3-none-any.whl (226 kB)\n","Using cached tyro-0.8.4-py3-none-any.whl (102 kB)\n","Using cached rich-13.7.1-py3-none-any.whl (240 kB)\n","Using cached shtab-1.7.1-py3-none-any.whl (14 kB)\n","Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n","Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n","Installing collected packages: shtab, mdurl, markdown-it-py, rich, tyro, trl\n","Successfully installed markdown-it-py-3.0.0 mdurl-0.1.2 rich-13.7.1 shtab-1.7.1 trl-0.9.4 tyro-0.8.4\n","Note: you may need to restart the kernel to use updated packages.\n","Collecting tensorboard\n","  Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n","Collecting absl-py>=0.4 (from tensorboard)\n","  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: grpcio>=1.48.2 in d:\\verba_1.01\\venv\\lib\\site-packages (from tensorboard) (1.64.0)\n","Collecting markdown>=2.6.8 (from tensorboard)\n","  Downloading Markdown-3.6-py3-none-any.whl.metadata (7.0 kB)\n","Requirement already satisfied: numpy>=1.12.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from tensorboard) (1.26.4)\n","Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in d:\\verba_1.01\\venv\\lib\\site-packages (from tensorboard) (4.25.3)\n","Requirement already satisfied: setuptools>=41.0.0 in d:\\verba_1.01\\venv\\lib\\site-packages (from tensorboard) (69.5.1)\n","Requirement already satisfied: six>1.9 in d:\\verba_1.01\\venv\\lib\\site-packages (from tensorboard) (1.16.0)\n","Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n","  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n","Collecting werkzeug>=1.0.1 (from tensorboard)\n","  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\verba_1.01\\venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n","Downloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n","   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n","   ---------------------------------------- 0.0/5.5 MB 991.0 kB/s eta 0:00:06\n","   -- ------------------------------------- 0.3/5.5 MB 3.4 MB/s eta 0:00:02\n","   ----- ---------------------------------- 0.7/5.5 MB 5.8 MB/s eta 0:00:01\n","   ----------- ---------------------------- 1.6/5.5 MB 9.9 MB/s eta 0:00:01\n","   ------------------ --------------------- 2.5/5.5 MB 11.6 MB/s eta 0:00:01\n","   --------------------- ------------------ 3.0/5.5 MB 11.1 MB/s eta 0:00:01\n","   ------------------------------ --------- 4.1/5.5 MB 13.2 MB/s eta 0:00:01\n","   ---------------------------------------  5.4/5.5 MB 15.0 MB/s eta 0:00:01\n","   ---------------------------------------- 5.5/5.5 MB 14.1 MB/s eta 0:00:00\n","Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n","   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n","   ---------------------------------------- 133.7/133.7 kB ? eta 0:00:00\n","Downloading Markdown-3.6-py3-none-any.whl (105 kB)\n","   ---------------------------------------- 0.0/105.4 kB ? eta -:--:--\n","   ---------------------------------------- 105.4/105.4 kB 5.9 MB/s eta 0:00:00\n","Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n","Downloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n","   ---------------------------------------- 0.0/227.3 kB ? eta -:--:--\n","   ---------------------------------------- 227.3/227.3 kB ? eta 0:00:00\n","Installing collected packages: werkzeug, tensorboard-data-server, markdown, absl-py, tensorboard\n","Successfully installed absl-py-2.1.0 markdown-3.6 tensorboard-2.17.0 tensorboard-data-server-0.7.2 werkzeug-3.0.3\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install pandas\n","%pip install datasets\n","%pip install seaborn\n","%pip install matplotlib\n","%pip install transformers\n","%pip install huggingface_hub\n","%pip install torch\n","%pip install peft\n","%pip install trl\n","%pip install tensorboard"]},{"cell_type":"markdown","metadata":{},"source":["### Inserting Your Hugging Face API Key\n","\n","To access the gated model, you need to use your Hugging Face API key. You can insert your API key by running the following code:"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\verba_1.01\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]},{"ename":"TypeError","evalue":"notebook_login() got an unexpected keyword argument 'token'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m token \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour_huggingface_api_key\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m notebook_login\n\u001b[1;32m----> 4\u001b[0m \u001b[43mnotebook_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mTypeError\u001b[0m: notebook_login() got an unexpected keyword argument 'token'"]}],"source":["# Insert your Hugging Face API key\n","token = \"your_huggingface_api_key\"\n","from huggingface_hub import notebook_login\n","notebook_login(token=token)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Step 1: Data Preparation\n","\n","In this step, we load the dataset, format the instructions and responses, and filter the examples based on token length."]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"Invalid token passed!","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[4], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124myour_huggingface_api_key\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Log in to Hugging Face and save the token to git credentials helper\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mlogin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_to_git_credential\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Initialize tokenizer\u001b[39;00m\n\u001b[0;32m     16\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3-8B\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[1;32mc:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\_login.py:111\u001b[0m, in \u001b[0;36mlogin\u001b[1;34m(token, add_to_git_credential, new_session, write_permission)\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m add_to_git_credential:\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    106\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe token has not been saved to the git credentials helper. Pass \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    107\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`add_to_git_credential=True` in this function directly or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`--add-to-git-credential` if using via `huggingface-cli` if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    109\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou want to set the git credential as well.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    110\u001b[0m         )\n\u001b[1;32m--> 111\u001b[0m     \u001b[43m_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_to_git_credential\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_to_git_credential\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_permission\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_permission\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_notebook():\n\u001b[0;32m    113\u001b[0m     notebook_login(new_session\u001b[38;5;241m=\u001b[39mnew_session, write_permission\u001b[38;5;241m=\u001b[39mwrite_permission)\n","File \u001b[1;32mc:\\Users\\risha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\_login.py:307\u001b[0m, in \u001b[0;36m_login\u001b[1;34m(token, add_to_git_credential, write_permission)\u001b[0m\n\u001b[0;32m    305\u001b[0m permission \u001b[38;5;241m=\u001b[39m get_token_permission(token)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m permission \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid token passed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m write_permission \u001b[38;5;129;01mand\u001b[39;00m permission \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mToken is valid but is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread-only\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m token is required.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease provide a new token with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m correct permission.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    312\u001b[0m     )\n","\u001b[1;31mValueError\u001b[0m: Invalid token passed!"]}],"source":["# Import necessary libraries\n","import pandas as pd\n","from datasets import Dataset\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from transformers import AutoTokenizer\n","from huggingface_hub import login\n","\n","# Replace 'your_huggingface_api_key' with your actual Hugging Face API key\n","api_key = 'your_huggingface_api_key'\n","\n","# Log in to Hugging Face and save the token to git credentials helper\n","login(token=api_key, add_to_git_credential=True)\n","\n","# Initialize tokenizer\n","base_model = \"meta-llama/Meta-Llama-3-8B\"\n","tokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=True)\n","tokenizer.pad_token = tokenizer.eos_token\n","tokenizer.padding_side = \"right\"\n","\n","def prepare_data(csv_path):\n","    df = pd.read_csv(csv_path)\n","\n","    df[\"formatted_instruction\"] = df.apply(lambda x: f\"### Instruction:\\n{x['Instructions']}\\n\\n### Response:\\n{x['Responses']}\", axis=1)\n","    df[\"formatted_instruction_tok_len\"] = df[\"formatted_instruction\"].apply(lambda x: len(tokenizer(x)[\"input_ids\"]))\n","\n","    sns.boxplot(x=df[\"formatted_instruction_tok_len\"])\n","    plt.xlabel(\"formatted_instruction_tok_len\")\n","    plt.title(\"Token Length\")\n","    plt.show()\n","\n","    df = df[df[\"formatted_instruction_tok_len\"] <= 128]\n","    dataset = Dataset.from_pandas(df)\n","    return dataset\n","\n","# Specify the path to your dataset\n","csv_path = 'path_to_your_dataset.csv'\n","# Prepare the dataset\n","dataset = prepare_data(csv_path)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Step 2: Model and Tokenizer Initialization\n","\n","Here, we initialize the model and tokenizer. We use 4-bit quantization for efficient training."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import necessary libraries\n","import torch\n","from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n","\n","# Set compute dtype\n","compute_dtype = torch.float16\n","\n","# Configure quantization\n","quant_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=compute_dtype,\n","    bnb_4bit_use_double_quant=False,\n",")\n","\n","# Load the model with quantization configuration\n","model = AutoModelForCausalLM.from_pretrained(\n","    base_model,\n","    quantization_config=quant_config,\n","    device_map={\"\": 0}\n",")\n","model.config.use_cache = False\n","model.config.pretraining_tp = 1"]},{"cell_type":"markdown","metadata":{},"source":["## Step 3: Calculate Model Size\n","\n","We define a function to calculate the model size in MB."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Function to calculate model size\n","def calculate_model_size(model):\n","    total_size = 0\n","    for param in model.parameters():\n","        param_size = param.numel() * param.element_size()\n","        total_size += param_size\n","    total_size_in_mb = total_size / (1024**2)\n","    return total_size_in_mb\n","\n","# Calculate and print model size\n","model_size_mb = calculate_model_size(model)\n","print(f\"Model size: {model_size_mb:.2f} MB\")"]},{"cell_type":"markdown","metadata":{},"source":["## Step 4: PEFT Configuration\n","\n","Set up PEFT parameters for training."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import necessary libraries\n","from peft import LoraConfig\n","\n","# Configure PEFT parameters\n","peft_params = LoraConfig(\n","    lora_alpha=16,\n","    lora_dropout=0.1,\n","    r=64,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Step 5: Training Arguments\n","\n","Set the training arguments."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import necessary libraries\n","from transformers import TrainingArguments\n","\n","# Set training arguments\n","training_params = TrainingArguments(\n","    output_dir=\"./\",\n","    num_train_epochs=1,\n","    per_device_train_batch_size=2,\n","    gradient_accumulation_steps=1,\n","    optim=\"paged_adamw_32bit\",\n","    save_steps=50,\n","    logging_steps=25,\n","    learning_rate=2e-4,\n","    weight_decay=0.001,\n","    fp16=False,\n","    bf16=False,\n","    max_grad_norm=0.3,\n","    max_steps=-1,\n","    warmup_ratio=0.03,\n","    group_by_length=True,\n","    lr_scheduler_type=\"constant\",\n","    report_to=\"tensorboard\"\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Step 6: SFTTrainer Setup and Training\n","\n","Initialize `SFTTrainer` and train the model."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import necessary libraries\n","from trl import SFTTrainer\n","import time\n","\n","# Initialize SFTTrainer\n","trainer = SFTTrainer(\n","    model=model,\n","    train_dataset=dataset,\n","    peft_config=peft_params,\n","    dataset_text_field=\"formatted_instruction\",\n","    max_seq_length=128,\n","    tokenizer=tokenizer,\n","    args=training_params,\n","    packing=False,\n",")\n","\n","# Train the model\n","start = time.time()\n","output = trainer.train()\n","print(\"Time taken: \", time.time() - start)"]},{"cell_type":"markdown","metadata":{},"source":["## Step 7: Monitor Training with Tensorboard\n","\n","Start Tensorboard for monitoring the training process."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Start Tensorboard for monitoring\n","from tensorboard import notebook\n","\n","log_dir = \"runs\"\n","notebook.start(\"--logdir {} --port 4000\".format(log_dir))"]},{"cell_type":"markdown","metadata":{},"source":["## Step 8: Generate Text Using the Trained Model\n","\n","Use the trained model to generate text based on a given prompt."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Import necessary libraries\n","from transformers import pipeline\n","\n","# Initialize text generation pipeline\n","pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer, max_length=100)\n","\n","# Define prompt\n","prompt = \"### Instruction:\\nPlease generate 5 variants of the question: 'What is the capital of France?'\\n\\n### Response\\n:\"\n","\n","# Generate text\n","gen_text = pipe(prompt)\n","print(gen_text[0]['generated_text'][len(prompt):])"]},{"cell_type":"markdown","metadata":{},"source":["### Implementation Notes\n","\n","- Ensure you have the required libraries installed (`transformers`, `datasets`, `peft`, `trl`, `seaborn`, `matplotlib`, `tensorboard`).\n","- Adjust the file path for your dataset in `csv_path`.\n","- The token length filter and other parameters can be adjusted based on your specific use case and dataset.\n","- Monitor the training process using Tensorboard to check for a gradual decline in training loss."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":4}
